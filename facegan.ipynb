{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-29T18:51:16.035783Z","iopub.execute_input":"2024-06-29T18:51:16.036081Z","iopub.status.idle":"2024-06-29T18:51:16.903461Z","shell.execute_reply.started":"2024-06-29T18:51:16.036039Z","shell.execute_reply":"2024-06-29T18:51:16.902516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:51:16.905169Z","iopub.execute_input":"2024-06-29T18:51:16.905621Z","iopub.status.idle":"2024-06-29T18:54:54.060746Z","shell.execute_reply.started":"2024-06-29T18:51:16.905588Z","shell.execute_reply":"2024-06-29T18:54:54.059661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tarfile\nmy_tar = tarfile.open('lfw.tgz')\nmy_tar.extractall('./lfw') # specify which folder to extract to\nmy_tar.close()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:54:54.062116Z","iopub.execute_input":"2024-06-29T18:54:54.062388Z","iopub.status.idle":"2024-06-29T18:54:59.001774Z","shell.execute_reply.started":"2024-06-29T18:54:54.062361Z","shell.execute_reply":"2024-06-29T18:54:59.000688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport PIL\nfrom tensorflow.keras import layers\nimport os\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:54:59.004364Z","iopub.execute_input":"2024-06-29T18:54:59.004801Z","iopub.status.idle":"2024-06-29T18:55:09.941928Z","shell.execute_reply.started":"2024-06-29T18:54:59.004768Z","shell.execute_reply":"2024-06-29T18:55:09.941118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ds(path):\n  img = tf.io.read_file(path)\n  img = tf.image.decode_jpeg(img,channels=3)\n  img = tf.image.convert_image_dtype(img,tf.float32)\n  img = tf.divide(tf.subtract(tf.multiply(img,255),127.5),127.5)\n  return tf.image.resize(img,(128,128)) \n\nimages = []\nfor i in os.scandir('lfw/lfw'):\n  for j in os.scandir(i.path):\n    images.append(j.path)\n\nimages = tf.data.Dataset.from_tensor_slices(images)\nBATCH_SIZE = 64\ntrain_images = images.map(get_ds,num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE).shuffle(60000)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:09.943026Z","iopub.execute_input":"2024-06-29T18:55:09.943582Z","iopub.status.idle":"2024-06-29T18:55:10.776185Z","shell.execute_reply.started":"2024-06-29T18:55:09.943554Z","shell.execute_reply":"2024-06-29T18:55:10.775405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.models.Sequential()\n    model.add(layers.Dense(8*8*128,input_shape=(100,),use_bias=False))    # creates output shape of 7,7 with number of neurons - [7,7,256]\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Reshape((8,8,128)))\n    assert model.output_shape == (None, 8, 8, 128)\n    \n    model.add(layers.Conv2DTranspose(64,(5,5),strides=(1,1),padding='same',use_bias=False))    # stride (1,1) keeps the same shape as that of input\n    assert model.output_shape == (None, 8, 8, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    ## output of shape (7,7,128)\n    \n    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))     # stride (2,2) doubles the size of the input \n    assert model.output_shape == (None, 16, 16, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    ## output shape (14,14,64)\n\n    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))     # stride (2,2) doubles the size of the input \n    assert model.output_shape == (None, 32, 32, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))     # stride (2,2) doubles the size of the input \n    assert model.output_shape == (None, 64, 64, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(3,(5,5),strides=(2,2),padding='same',activation='tanh',use_bias=False))\n    assert model.output_shape == (None, 128, 128, 3)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:10.777225Z","iopub.execute_input":"2024-06-29T18:55:10.777502Z","iopub.status.idle":"2024-06-29T18:55:10.788412Z","shell.execute_reply.started":"2024-06-29T18:55:10.777478Z","shell.execute_reply":"2024-06-29T18:55:10.787566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model()\nnoise = tf.random.normal([1,100])\ngenerated_image = generator(noise,training=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:10.789370Z","iopub.execute_input":"2024-06-29T18:55:10.789631Z","iopub.status.idle":"2024-06-29T18:55:12.215864Z","shell.execute_reply.started":"2024-06-29T18:55:10.789609Z","shell.execute_reply":"2024-06-29T18:55:12.214659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(generated_image[0]*127.5+127.5)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.217447Z","iopub.execute_input":"2024-06-29T18:55:12.217761Z","iopub.status.idle":"2024-06-29T18:55:12.552991Z","shell.execute_reply.started":"2024-06-29T18:55:12.217736Z","shell.execute_reply":"2024-06-29T18:55:12.552105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_discriminator_model():\n  model = tf.keras.models.Sequential()\n  model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=[128,128,3]))\n  model.add(layers.LeakyReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same'))\n  model.add(layers.LeakyReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Flatten())\n  model.add(layers.Dense(1))\n\n  return model","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.554032Z","iopub.execute_input":"2024-06-29T18:55:12.554329Z","iopub.status.idle":"2024-06-29T18:55:12.561370Z","shell.execute_reply.started":"2024-06-29T18:55:12.554305Z","shell.execute_reply":"2024-06-29T18:55:12.560497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\nprint(decision)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.564805Z","iopub.execute_input":"2024-06-29T18:55:12.565091Z","iopub.status.idle":"2024-06-29T18:55:12.783630Z","shell.execute_reply.started":"2024-06-29T18:55:12.565047Z","shell.execute_reply":"2024-06-29T18:55:12.782791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.784663Z","iopub.execute_input":"2024-06-29T18:55:12.784950Z","iopub.status.idle":"2024-06-29T18:55:12.789586Z","shell.execute_reply.started":"2024-06-29T18:55:12.784927Z","shell.execute_reply":"2024-06-29T18:55:12.788589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output,fake_output):\n  real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n  fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n  total_loss = real_loss + fake_loss\n  return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.790562Z","iopub.execute_input":"2024-06-29T18:55:12.790819Z","iopub.status.idle":"2024-06-29T18:55:12.799659Z","shell.execute_reply.started":"2024-06-29T18:55:12.790788Z","shell.execute_reply":"2024-06-29T18:55:12.798891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(fake_output):\n  return cross_entropy(tf.ones_like(fake_output),fake_output)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.800797Z","iopub.execute_input":"2024-06-29T18:55:12.801533Z","iopub.status.idle":"2024-06-29T18:55:12.810656Z","shell.execute_reply.started":"2024-06-29T18:55:12.801503Z","shell.execute_reply":"2024-06-29T18:55:12.809757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(2e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(0.0005)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.811726Z","iopub.execute_input":"2024-06-29T18:55:12.812316Z","iopub.status.idle":"2024-06-29T18:55:12.825659Z","shell.execute_reply.started":"2024-06-29T18:55:12.812285Z","shell.execute_reply":"2024-06-29T18:55:12.824877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ncheckpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.826792Z","iopub.execute_input":"2024-06-29T18:55:12.827133Z","iopub.status.idle":"2024-06-29T18:55:12.832822Z","shell.execute_reply.started":"2024-06-29T18:55:12.827103Z","shell.execute_reply":"2024-06-29T18:55:12.832113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1000\nnoise_dims = 100\nnum_egs_to_generate = 16\nseed = tf.random.normal([num_egs_to_generate,noise_dims])","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.833839Z","iopub.execute_input":"2024-06-29T18:55:12.834147Z","iopub.status.idle":"2024-06-29T18:55:12.843450Z","shell.execute_reply.started":"2024-06-29T18:55:12.834120Z","shell.execute_reply":"2024-06-29T18:55:12.842719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(images):\n  noise = tf.random.normal([BATCH_SIZE,noise_dims])\n\n  with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n    generated_images = generator(noise,training=True)\n\n    real_output = discriminator(images,training=True)\n    fake_output = discriminator(generated_images,training=True)\n\n    gen_loss = generator_loss(fake_output)\n    disc_loss = discriminator_loss(real_output,fake_output)\n\n  gen_gradients = gen_tape.gradient(gen_loss,generator.trainable_variables)\n  dis_gradients = dis_tape.gradient(disc_loss,discriminator.trainable_variables)\n\n  generator_optimizer.apply_gradients(zip(gen_gradients,generator.trainable_variables))\n  discriminator_optimizer.apply_gradients(zip(dis_gradients,discriminator.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.844543Z","iopub.execute_input":"2024-06-29T18:55:12.844909Z","iopub.status.idle":"2024-06-29T18:55:12.853868Z","shell.execute_reply.started":"2024-06-29T18:55:12.844885Z","shell.execute_reply":"2024-06-29T18:55:12.853188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython import display\nimport time\ndef train(dataset,epochs):\n  for epoch in range(epochs):\n    start = time.time()\n    for batch in dataset:\n      train_step(batch)\n    display.clear_output(wait=True)\n    generate_and_save_output(generator,epoch+1,seed)\n\n    if (epoch+1)%100 == 0:\n      checkpoint.save(file_prefix=checkpoint_prefix)\n\n    print(f'Time for epoch {epoch + 1} is {time.time()-start}')\n  \n  display.clear_output(wait=True)\n  generate_and_save_output(generator,epochs,seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.854869Z","iopub.execute_input":"2024-06-29T18:55:12.855161Z","iopub.status.idle":"2024-06-29T18:55:12.867486Z","shell.execute_reply.started":"2024-06-29T18:55:12.855138Z","shell.execute_reply":"2024-06-29T18:55:12.866588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_output(model,epoch,test_input):\n\n  predictions = model(test_input,training=False)\n  # predictions = predictions.numpy().reshape(16,64,64,1)\n  fig = plt.figure(figsize=(4,4))\n  # print(predictions)\n  for i in range(predictions.shape[0]):\n    plt.subplot(4,4,i+1)\n    plt.imshow((predictions[i]*127.5+127.5).numpy().astype(np.uint8),cmap='gray')\n    plt.axis('off')\n  plt.savefig(f'image_at_epoch_{epoch}.png')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.868437Z","iopub.execute_input":"2024-06-29T18:55:12.868672Z","iopub.status.idle":"2024-06-29T18:55:12.878660Z","shell.execute_reply.started":"2024-06-29T18:55:12.868651Z","shell.execute_reply":"2024-06-29T18:55:12.877751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(train_images,EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:55:12.879711Z","iopub.execute_input":"2024-06-29T18:55:12.880049Z","iopub.status.idle":"2024-06-29T19:03:22.318250Z","shell.execute_reply.started":"2024-06-29T18:55:12.880020Z","shell.execute_reply":"2024-06-29T19:03:22.317042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio\nimport glob\nanim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  last = -1\n  for i,filename in enumerate(filenames):\n    frame = 2*(i**0.5)\n    if round(frame) > round(last):\n      last = frame\n    else:\n      continue\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\nimport IPython\nif IPython.version_info > (6,2,0,''):\n  display.Image(filename=anim_file)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T19:03:22.319252Z","iopub.status.idle":"2024-06-29T19:03:22.319612Z","shell.execute_reply.started":"2024-06-29T19:03:22.319430Z","shell.execute_reply":"2024-06-29T19:03:22.319444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.save('/kaggle/working/generator.keras')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_image = generator(tf.random.normal([1,100]),training=False)\nplt.imshow((new_image[0]*127.5+127.5).numpy().astype(np.uint8))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T19:03:22.321234Z","iopub.status.idle":"2024-06-29T19:03:22.321557Z","shell.execute_reply.started":"2024-06-29T19:03:22.321399Z","shell.execute_reply":"2024-06-29T19:03:22.321412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}